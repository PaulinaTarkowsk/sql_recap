{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1Wt3iRpEKW2J8K7wpy4UE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaulinaTarkowsk/sql_recap/blob/main/hyperparametrs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Wyszukiwanie siatkowe**"
      ],
      "metadata": {
        "id": "u3PX4by-pEK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Głównymi argumentami konstruktora GridSearchCV są:**\n",
        "\n",
        "**estimator** - jest to obiekt modelu, który zostanie dopasowany do danych. Może to być dowolny model z biblioteki scikit-learn, który posiada metody fit() i predict().\n",
        "\n",
        "**param_grid** - jest to słownik lub lista słowników, w którym każdy klucz to nazwa hiperparametru, a wartość to lista wartości, które chcemy przetestować. GridSearchCV przetestuje wszystkie możliwe kombinacje tych wartości.\n",
        "\n",
        "**scoring** - określa miarę jakości, która będzie używana do oceny modelu dla każdej kombinacji hiperparametrów. Może to być jedna z wbudowanych miar, takich jak accuracy czy mean_squared_error, lub niestandardowa funkcja oceny. Lista gotowych do użycia metryk, które możemy przekazać do tego argumentu, znajduje się tu.\n",
        "\n",
        "**cv** - określa schemat podziału danych do walidacji krzyżowej. Może to być liczba podziałów (np. 5 dla walidacji krzyżowej 5-krotnej) lub obiekt generatora walidacji krzyżowej.\n",
        "\n",
        "**n_jobs** - określa liczbę procesów, które mają być użyte do przeprowadzenia obliczeń w trakcie przeszukiwania siatki. Wartość -1 oznacza, że zostaną wykorzystane wszystkie dostępne procesory.\n",
        "\n",
        "\n",
        "# **Klasa GridSearchCV udostępnia również kilka przydatnych metod, takich jak:**\n",
        "\n",
        "**fit(X, y):** Metoda ta dopasowuje model do danych treningowych, przeprowadzając przeszukiwanie siatki hiperparametrów i oceniając model dla każdej kombinacji. Po zakończeniu dostępne są atrybuty, takie jak **best_params_, best_score_ i best_estimator_**, które zawierają odpowiednio najlepsze znalezione wartości hiperparametrów, wynik i najlepszy dopasowany model.\n",
        "\n",
        "**predict(X):** Metoda ta dokonuje predykcji na podstawie danych X za pomocą najlepszego znalezionego modelu.\n",
        "\n",
        "**score(X, y):** Metoda ta oblicza wynik modelu na podstawie danych X i etykiet y za pomocą domyślnej miary jakości.\n"
      ],
      "metadata": {
        "id": "lEAu2lQmpPjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Przykład użycia GridSearchCV dla algorytmu drzewa decyzyjnego:\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameters grid to find the best set\n",
        "params_grid = {\n",
        "    'max_depth': np.arange(3, 21, 2), # list of integers from 3 to 19 with step = 2\n",
        "    'criterion': [\"entropy\", \"gini\"],\n",
        "    'max_features': [None, \"log2\", \"sqrt\"],\n",
        "}\n",
        "\n",
        "# Create a model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(model, params_grid, cv=5, scoring=\"recall\")\n",
        "\n",
        "# Fit training data using grid_search object\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best hyperparameters set found during grid search\n",
        "best_params = grid_search.best_params_\n"
      ],
      "metadata": {
        "id": "yc9WuyQBrUdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Wyszukiwanie losowe**"
      ],
      "metadata": {
        "id": "3Hk7FHIgq8qQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Głównymi argumentami konstruktora klasy RandomizedSearchCV są:**\n",
        "\n",
        "**estimator** — to obiekt modelu, który zostanie dopasowany do danych. Może to być dowolny model z biblioteki scikit-learn, który posiada metody **.fit() i .predict()**.\n",
        "\n",
        "**param_distributions** — to słownik, w którym każdy klucz to nazwa hiperparametru, a wartość to rozkład prawdopodobieństwa lub lista wartości, które chcemy przetestować. RandomizedSearchCV losowo próbuje różne kombinacje wartości hiperparametrów z zadanego zakresu.\n",
        "\n",
        "**n_iter** — określa liczbę iteracji, czyli liczbę prób losowych kombinacji wartości hiperparametrów do przetestowania.\n",
        "\n",
        "**scoring** — określa miarę jakości, która będzie używana do oceny modelu dla każdej kombinacji hiperparametrów. Może to być jedna z wbudowanych miar, takich jak accuracy czy mean_squared_error, lub niestandardowa funkcja oceny.\n",
        "\n",
        "**cv** — określa schemat podziału danych do walidacji krzyżowej. Może to być liczba podziałów (np. 5 dla walidacji krzyżowej 5-krotnej) lub obiekt generatora walidacji krzyżowej.\n",
        "\n",
        "**n_jobs** — określa liczbę procesów, które mają być użyte do przeprowadzenia obliczeń w trakcie przeszukiwania losowego. Wartość -1 oznacza, że zostaną wykorzystane wszystkie dostępne procesory.\n",
        "\n",
        "#**Klasa RandomizedSearchCV ma zaimplementowane analogiczne metody jak GridSearchCV**\n"
      ],
      "metadata": {
        "id": "5_56PlsOrWGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Przykład użycia RandomizedSearchCV dla maszyny wektorów nośnych:\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Define hyperparameters params dict\n",
        "param_dist = {\n",
        "    'C': uniform(loc=0, scale=4),\n",
        "    'gamma': uniform(loc=0, scale=0.1),\n",
        "}\n",
        "\n",
        "# Create a model instance\n",
        "model = SVC()\n",
        "\n",
        "# Create RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(model, param_dist, n_iter=10, cv=5)\n",
        "\n",
        "# Fit model to training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# The best set of hyperparameters found\n",
        "best_params = random_search.best_params_\n"
      ],
      "metadata": {
        "id": "RHDUrV7ksF6a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Wyszukiwanie bayesowskie**"
      ],
      "metadata": {
        "id": "tAbe0j39sNEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all needed methods from hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials, space_eval\n",
        "\n",
        "# Define hyperparameter space\n",
        "space = {\n",
        "    'min_samples_split': hp.uniform('min_samples_split', 5, 15),\n",
        "    'min_samples_leaf': hp.choice('min_samples_leaf', [20, 30, 40]),\n",
        "    'max_depth': hp.choice('max_depth', [None, 5, 10]),\n",
        "    'criterion': hp.choice('criterion', ['gini', 'entropy'])\n",
        "}\n",
        "\n",
        "# Define function that measure chosen metric for given hyperparameter combination\n",
        "\n",
        "def objective(params):\n",
        "    # Create a model. Here: decision tree classifier\n",
        "    model = DecisionTreeClassifier(params)\n",
        "\n",
        "    # Fit model using training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Calculate chosen metric\n",
        "    score = model.score(X_val, y_val) # val is a shortcut from validation\n",
        "\n",
        "    # Return score with \"-\". As we want to maximize our metric,\n",
        "    # but bayesian optimization goal is to minimize function, we need add minus sign\n",
        "    return -score\n",
        "\n",
        "# Initializer Trials object due to store all iterations and use them to further optimizations\n",
        "trials = Trials()\n",
        "\n",
        "# Call optimization function\n",
        "best = fmin(\n",
        "    fn=objective,\n",
        "    space=space,\n",
        "    max_evals=50,\n",
        "    trails=trials\n",
        ")\n",
        "\n",
        "# Get best hyperparameters set found\n",
        "best_params = space_eval(space, best)\n"
      ],
      "metadata": {
        "id": "2YMPN1Pbsh0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**W powyższym przykładzie korzystaliśmy z metod, których wcześniej nie znaliśmy. Poniżej wyjaśnienie, za co odpowiedzialne są poszczególne fragmenty kodu:**\n",
        "\n",
        "**space** — definiuje przestrzeń poszukiwań hiperparametrów, gdzie dla każdego hiperparametru określamy rodzaj rozkładu (hp.loguniform, hp.choice itp.) oraz zakres wartości.\n",
        "\n",
        "**hp.choice(label, options)** — definiuje rozkład dyskretny, gdzie options to lista możliwych wartości dla hiperparametru,\n",
        "\n",
        "**hp.uniform(label, low, high)** — definiuje rozkład jednostajny, gdzie wartości są generowane równomiernie między low a high,\n",
        "\n",
        "**hp.randint(label, upper)** — definiuje rozkład całkowity, gdzie wartości są generowane jako liczby całkowite z zakresu od 0 do upper.\n",
        "\n",
        "**hp.normal(label, mu, sigma)** — definiuje rozkład normalny o zadanych wartościach średniej (mu) i odchylenia standardowego (sigma).\n",
        "\n",
        "**objective** — funkcja oceny, która przyjmuje jako argument zestaw hiperparametrów i ocenia wynik modelu dla danej kombinacji.\n",
        "\n",
        "**trials** — to obiekt Trials, który śledzi postęp optymalizacji i przechowuje wyniki dla każdej iteracji.\n",
        "\n",
        "**fmin** — to główna funkcja biblioteki hyperopt, która przeprowadza proces optymalizacji. Przyjmuje argumenty takie jak:\n",
        "\n",
        "**fn** — funkcja oceny,\n",
        "\n",
        "**space** — przestrzeń poszukiwań hiperparametrów,\n",
        "\n",
        "**max_evals** — maksymalna liczba iteracji do wykonania,\n",
        "\n",
        "**trials** — obiekt Trials."
      ],
      "metadata": {
        "id": "MgG0tvgQsm1_"
      }
    }
  ]
}